{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distance hist 500 [clelia not sure if smart idea, so do this to test the idea]\n",
    "    - [ ] 10 runs MCM 0 for 500 samples, overlap co- ocurrence matrices, calculate expected number icc and cluster to this amount\n",
    "    - [ ] Then use new-found “average mcm”.\n",
    "    - [ ] From all samples used, take union of unique elements (so exclude the ones we did not see and remove duplicates) and recalculate counts and Len data\n",
    "    - [ ] Now compare the distance hist we get for 500 with the one from a single run 5k -> compare against all digits and single some out like last time\n",
    "    - [ ] Goal: want to know if this average mcm is really needed instead of just using a single run one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import src.plot as myplot\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.plot' from '/Users/paulhosek/PycharmProjects/mcm/MCM_classifier/Classifier_1/0_classifier/paper_plots/../src/plot.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import src.plot as myplot\n",
    "importlib.reload(myplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.paper_utils' from '/Users/paulhosek/PycharmProjects/mcm/MCM_classifier/Classifier_1/0_classifier/paper_plots/../src/paper_utils.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import importlib\n",
    "import src.paper_utils as utils\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [500, 5000]\n",
    "counts_samplesizes, mcms_samplesizes = utils.load_counts_mcm(sample_sizes, letter=\"\", path_format=\"../Output/sample_sizes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcm_digit = 0\n",
    "mcms_500 = mcms_samplesizes[sample_sizes.index(500)]\n",
    "nr_runs = len(mcms_500)\n",
    "\n",
    "coo_500 = np.array([myplot.create_cooccurance_matrix(mcms_500[i][mcm_digit]) for i in range(nr_runs)],dtype=int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.spatial.distance import pdist\n",
    "import numpy as np\n",
    "\n",
    "mean_nr_icc = np.mean([len(mcm[mcm_digit]) for mcm in mcms_500])\n",
    "\n",
    "m = coo_500.sum(axis=0)\n",
    "linkage = sch.linkage(m, method=\"ward\")\n",
    "labels = sch.fcluster(linkage, t=mean_nr_icc, criterion=\"maxclust\")\n",
    "sorted_indices = np.argsort(labels)\n",
    "sorted_m = m[sorted_indices[:,None],sorted_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mcm = labels.reshape((11,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_mcm.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show training set and construct counts\n",
    "# get training set for each 500 using the seed, get the union without duplicates\n",
    "# construct counts\n",
    "\n",
    "# utils.recreate_dataset(\"\",0,500,seed=s, fname_format = \"train-images-unlabled-{}.dat\",fname_start=\"train-\")\n",
    "# utils.subsample_data(500, all_data_path=\"../INPUT_all/data\", input_data_path=\"../INPUT/data\", seed=42,fname_start = \"train-\")\n",
    "samp = np.array([utils.recreate_dataset(\"\",mcm_digit, 500, seed = s+1,fname_format= \"train-images-unlabeled-{}.dat\", fname_start=\"train-\", all_data_path=\"../INPUT_all/data/\", input_data_path = \"../INPUT/data/\") for s in range(10)])\n",
    "samp = np.unique(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def partition_to_str(mcm):\n",
    "    \"\"\"Take a partition map labeling 11x11 array and return the original string representation\"\"\"\n",
    "    nr_icc = mcm.max()\n",
    "    out = []\n",
    "\n",
    "    for icc in range(1, nr_icc+1):\n",
    "        idx = np.argwhere(mcm.flatten()==icc).flatten()\n",
    "        x = np.zeros(121,dtype=int)\n",
    "        x[idx] = 1\n",
    "        out.append(\"\".join(map(str, x)))\n",
    "    return np.array(out, dtype=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "icc = 1\n",
    "samp_gen = np.genfromtxt(samp, delimiter=1, dtype=int)\n",
    "n_variables = avg_mcm.max()\n",
    "Counts = []\n",
    "for icc in range(1, n_variables+1):\n",
    "    idc = np.argwhere(avg_mcm.flatten()==icc).flatten()\n",
    "    p_count = np.zeros(2**len(idc))\n",
    "    icc_strings = [int(\"\".join([str(s) for s in state]), 2) for state in samp_gen[:,idc]]\n",
    "\n",
    "    u,c = np.unique(icc_strings, return_counts=True)\n",
    "\n",
    "    p_count[u] = c  \n",
    "    Counts.append(list(p_count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute distance hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "n_runs = 10\n",
    "mcm_digit = 0\n",
    "\n",
    "nr_digits = 10\n",
    "sample_sizes = [5000]\n",
    "\n",
    "test_probs = np.zeros((len(sample_sizes), n_runs,nr_digits, len(utils.load_test_data(digit=0))))\n",
    "\n",
    "for test_digit in range(nr_digits):\n",
    "    test_data = utils.load_test_data(digit=test_digit)\n",
    "\n",
    "    for sample_size_idx, sample_size in enumerate(sample_sizes):\n",
    "\n",
    "        mcms = mcms_samplesizes[sample_size_idx][:n_runs]\n",
    "        counts_gstar = counts_samplesizes[sample_size_idx][:n_runs]\n",
    "            \n",
    "        for run_idx, mcm in enumerate(mcms):\n",
    "            test_probs[sample_size_idx][run_idx][test_digit] = utils.probabilities_gstar(mcm[mcm_digit], counts_gstar[run_idx][mcm_digit], test_data, sample_size,smooth=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_probs_avg500 = utils.probabilities_gstar(list(partition_to_str(avg_mcm)), Counts, test_data, len(samp),smooth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcm_classifying",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
