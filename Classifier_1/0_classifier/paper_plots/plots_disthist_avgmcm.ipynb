{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distance hist 500 [clelia not sure if smart idea, so do this to test the idea]\n",
    "    - [ ] 10 runs MCM 0 for 500 samples, overlap co- ocurrence matrices, calculate expected number icc and cluster to this amount\n",
    "    - [ ] Then use new-found “average mcm”.\n",
    "    - [ ] From all samples used, take union of unique elements (so exclude the ones we did not see and remove duplicates) and recalculate counts and Len data\n",
    "    - [ ] Now compare the distance hist we get for 500 with the one from a single run 5k -> compare against all digits and single some out like last time\n",
    "    - [ ] Goal: want to know if this average mcm is really needed instead of just using a single run one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import src.plot as myplot\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.plot' from '/Users/paulhosek/PycharmProjects/mcm/MCM_classifier/Classifier_1/0_classifier/paper_plots/../src/plot.py'>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import src.plot as myplot\n",
    "importlib.reload(myplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.paper_utils' from '/Users/paulhosek/PycharmProjects/mcm/MCM_classifier/Classifier_1/0_classifier/paper_plots/../src/paper_utils.py'>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import importlib\n",
    "import src.paper_utils as utils\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [500, 5000]\n",
    "counts_samplesizes, mcms_samplesizes = utils.load_counts_mcm(sample_sizes, letter=\"\", path_format=\"../Output/sample_sizes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcm_digit = 0\n",
    "mcms_500 = mcms_samplesizes[sample_sizes.index(500)]\n",
    "nr_runs = len(mcms_500)\n",
    "\n",
    "coo_500 = np.array([myplot.create_cooccurance_matrix(mcms_500[i][mcm_digit]) for i in range(nr_runs)],dtype=int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.spatial.distance import pdist\n",
    "import numpy as np\n",
    "\n",
    "mean_nr_icc = np.mean([len(mcm[mcm_digit]) for mcm in mcms_500])\n",
    "\n",
    "m = coo_500.sum(axis=0)\n",
    "linkage = sch.linkage(m, method=\"ward\")\n",
    "labels = sch.fcluster(linkage, t=mean_nr_icc, criterion=\"maxclust\")\n",
    "sorted_indices = np.argsort(labels)\n",
    "sorted_m = m[sorted_indices[:,None],sorted_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mcm = labels.reshape((11,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_mcm.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show training set and construct counts\n",
    "# get training set for each 500 using the seed, get the union without duplicates\n",
    "# construct counts\n",
    "\n",
    "# utils.recreate_dataset(\"\",0,500,seed=s, fname_format = \"train-images-unlabled-{}.dat\",fname_start=\"train-\")\n",
    "# utils.subsample_data(500, all_data_path=\"../INPUT_all/data\", input_data_path=\"../INPUT/data\", seed=42,fname_start = \"train-\")\n",
    "samp = np.array([utils.recreate_dataset(\"\",mcm_digit, 500, seed = s+1,fname_format= \"train-images-unlabeled-{}.dat\", fname_start=\"train-\", all_data_path=\"../INPUT_all/data/\", input_data_path = \"../INPUT/data/\") for s in range(5)])\n",
    "samp = np.unique(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def partition_to_str(mcm):\n",
    "    \"\"\"Take a partition map labeling 11x11 array and return the original string representation\"\"\"\n",
    "    nr_icc = mcm.max()\n",
    "    out = []\n",
    "\n",
    "    for icc in range(nr_icc):\n",
    "        idx = np.argwhere(mcm.flatten()==icc).flatten()\n",
    "        x = np.zeros(121,dtype=int)\n",
    "        x[idx] = 1\n",
    "        out.append(\"\".join(map(str, x)))\n",
    "    return np.array(out, dtype=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0000000000000000000000000000000000000000111100001100000001100001000110000100001000011000011111000000000000000000000000000',\n",
       "       '0000000000000000000000000000000000000011111000011110110001100000110110000111001100111000011111000000000000000000000000000',\n",
       "       '0000000000000000000000000000000000000100010000100000010010000000010100000000100111111110000000000000000000000000000000000',\n",
       "       ...,\n",
       "       '0011000000001111110000011100110000110000110001000000100011000000100011000001000011000001000011100110000011111000000000100',\n",
       "       '0100000000000000111000000111111000001100011000110000110001100001100110000011001100000110011100011000011111100000000000000',\n",
       "       '1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111'],\n",
       "      dtype='<U121')"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False,  True,  True,\n",
       "        True, False, False, False])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(avg_mcm.flatten()==icc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "icc = 1\n",
    "samp_gen = np.genfromtxt(samp, delimiter=1, dtype=int)\n",
    "n_variables = avg_mcm.max()\n",
    "Counts = []\n",
    "for icc in range(1, n_variables+1):\n",
    "    idc = np.argwhere(avg_mcm.flatten()==icc).flatten()\n",
    "    p_count = np.zeros(2**len(idc))\n",
    "    icc_strings = [int(\"\".join([str(s) for s in state]), 2) for state in samp_gen[:,idc]]\n",
    "\n",
    "    u,c = np.unique(icc_strings, return_counts=True)\n",
    "\n",
    "    p_count[u] = c  \n",
    "    Counts.append(list(p_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# co_matrix = coo_500\n",
    "\n",
    "\n",
    "\n",
    "# distance_matrix = 1 - co_matrix / co_matrix.max() \n",
    "# model = AgglomerativeClustering(n_clusters=5, affinity=\"euclidean\", linkage=\"ward\")\n",
    "# model.fit(distance_matrix)\n",
    "# cluster_labels = model.labels_\n",
    "\n",
    "# order_label = np.argsort(cluster_labels) # ties not handled well\n",
    "# reordered_matrix = co_matrix[order_label[:, None], order_label]\n",
    "\n",
    "# # plt.imshow(reordered_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcm_classifying",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
